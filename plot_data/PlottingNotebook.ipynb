{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPCay2GNIDTj90ol8ZXwYTx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"qkdVkYYaWzIX","executionInfo":{"status":"ok","timestamp":1686317621692,"user_tz":-120,"elapsed":2175,"user":{"displayName":"Birk Dissing","userId":"01780693664927861227"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from birdCLEFloaddata import load_audiofile,load_metadata,get_melspectrogram\n","from birdCLEFFunctions import Dynamic_CNN, Dynamic_CNN2\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision.transforms import Resize\n","from torch.utils.data import DataLoader, TensorDataset\n","from efficientnet_pytorch import EfficientNet\n","from torchvision.transforms import Grayscale, ToPILImage\n","import torchvision\n","import soundfile as sf\n","import random\n","import math\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n","\n","plt.rcParams['figure.dpi'] = 600"]},{"cell_type":"code","source":["from google.colab import drive, files\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IGT_sdZCXOu8","executionInfo":{"status":"ok","timestamp":1686317653553,"user_tz":-120,"elapsed":27217,"user":{"displayName":"Birk Dissing","userId":"01780693664927861227"}},"outputId":"494bdf26-f802-4b83-f511-3c05514912da"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!unzip /content/drive/MyDrive/APP_ML/APPML-BirdCLEF/data2022/BirdCLEF2023.zip -d birdclef2023"],"metadata":{"id":"fL-RbbuubZkl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import zipfile"],"metadata":{"id":"hMQ7ZbhQbbOS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import sys\n","sys.path.append('/content/drive/MyDrive/APP_ML/APPML-BirdCLEF/CodeEffecientnet')"],"metadata":{"id":"uS7FtY4tbbmW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_metadata(directory,datadir, trim=False):\n","    if trim:\n","        df = pd.read_csv(directory+'/train_metadata_trim.csv')\n","    else:\n","        df = pd.read_csv(directory+'/train_metadata.csv')\n","    df['filename'] = datadir+\"/train_audio/\"+df['filename']\n","    chosen_coloumns = ['latitude', 'longitude', 'common_name', 'rating', 'filename']\n","    return df[chosen_coloumns]\n","\n","path = r\"/content/birdclef2023\"\n","meta_data = load_metadata(path,path,trim=True)"],"metadata":{"id":"WlOX0Fnzbmm0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the duration of each segment in seconds\n","segment_duration = 15\n","max_files_per_bird = 50\n","\n","# Generate audio data\n","training_data = []\n","validation_data = []\n","birds_with_single_clip = []\n","random.seed(42)\n","# Iterate through each unique bird\n","\n","for i, bird in enumerate(meta_data['common_name'].unique()):\n","    print(i+1, \"/\", len(meta_data['common_name'].unique()))\n","    # Get all audio clips for the bird\n","    bird_clips = meta_data[meta_data['common_name'] == bird]['filename'].tolist()\n","    # If the bird has only one clip, split it into two halves\n","    if len(bird_clips) == 1:\n","        birds_with_single_clip.append(bird)\n","    else:\n","        # Randomly select one clip for validation and the rest for training\n","        random.shuffle(bird_clips)\n","        training_clip = bird_clips[1:]\n","        validation_clip = bird_clips[0]\n","\n","    # Load and process the training clip\n","    num_files_sampled = 0\n","    for clip in training_clip:\n","        if num_files_sampled >= max_files_per_bird:\n","            break\n","        train_audio, sr = load_audiofile(clip)\n","        num_segments = math.floor(len(train_audio) / (segment_duration * sr))\n","        if num_segments == 0:\n","          start_time = 0\n","          end_time = segment_duration\n","          pad_size = (segment_duration * sr) - train_audio.shape[0]\n","          train_audio = np.pad(train_audio, (0,pad_size), mode='wrap')\n","          segment_audio = train_audio[start_time * sr:end_time * sr]\n","          training_data.append([get_melspectrogram(segment_audio), bird])\n","        else:\n","          for segment in range(num_segments):\n","            start_time = segment * segment_duration\n","            end_time = start_time + segment_duration\n","            segment_audio = train_audio[start_time * sr:end_time * sr]\n","            training_data.append([get_melspectrogram(segment_audio), bird])\n","        num_files_sampled += 1\n","\n","    # Load and process the validation clip\n","    validation_audio, sr = load_audiofile(validation_clip)\n","    num_segments = math.floor(len(validation_audio) / (segment_duration * sr))\n","    if num_segments == 0:\n","      start_time = 0\n","      end_time = segment_duration\n","      pad_size = (segment_duration * sr) - validation_audio.shape[0]\n","      validation_audio = np.pad(validation_audio, (0,pad_size), mode='wrap')\n","      segment_audio = validation_audio[start_time * sr:end_time * sr]\n","      validation_data.append([get_melspectrogram(segment_audio), bird])\n","    else:\n","      for segment in range(num_segments):\n","        start_time = segment * segment_duration\n","        end_time = start_time + segment_duration\n","        segment_audio = validation_audio[start_time * sr:end_time * sr]\n","        validation_data.append([get_melspectrogram(segment_audio), bird])\n","\n","# Split the single clips into training and validation\n","random.shuffle(birds_with_single_clip)\n","split_index = len(birds_with_single_clip) // 2\n","training_single_clips = birds_with_single_clip[split_index:]\n","validation_single_clips = birds_with_single_clip[:split_index]\n","\n","# Append the single clips to the training and validation data\n","for bird in birds_with_single_clip:\n","    if len(training_data) >= max_files_per_bird:\n","        break\n","    clip = meta_data[meta_data['common_name'] == bird]['filename'].tolist()[0]\n","    audio, sr = load_audiofile(clip)\n","    num_segments = math.floor(len(audio) / (segment_duration * sr))\n","    if num_segments == 0:\n","      start_time = 0\n","      end_time = segment_duration\n","      pad_size = (segment_duration * sr) - validation_audio.shape[0]\n","      validation_audio = np.pad(validation_audio, (0,pad_size), mode='wrap')\n","      segment_audio = validation_audio[start_time * sr:end_time * sr]\n","      validation_data.append([get_melspectrogram(segment_audio), bird])\n","      training_data.append([get_melspectrogram(segment_audio), bird])\n","    else:\n","      for segment in range(num_segments):\n","        start_time = segment * segment_duration\n","        end_time = start_time + segment_duration\n","        segment_audio = audio[start_time * sr:end_time * sr]\n","        validation_data.append([get_melspectrogram(segment_audio), bird])\n","        training_data.append([get_melspectrogram(segment_audio), bird])\n","\n","# Convert to numpy arrays\n","training_data = np.asarray(training_data)\n","validation_data = np.asarray(validation_data)\n","\n","# Map labels to indices\n","label_mapping = {label: index for index, label in enumerate(set(meta_data['common_name'].unique()))}\n","training_data[:, 1] = [label_mapping.get(label, -1) + 1 for label in training_data[:, 1]]\n","validation_data[:, 1] = [label_mapping.get(label, -1) + 1 for label in validation_data[:, 1]]\n","\n","# Clear temporary data and variables\n","birds_with_single_clip = None\n","training_single_clips = None\n","validation_single_clips = None"],"metadata":{"id":"eXML2e0McWBw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["val_probabilities = np.read('/content/drive/MyDrive/APP_ML/APPML-BirdCLEF/plot_data/val_probabilities')\n","val_true_labels = np.read('/content/drive/MyDrive/APP_ML/APPML-BirdCLEF/plot_data/val_true_labels')"],"metadata":{"id":"YIVwqDsUXEWc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"7oBzIkM-Xmtl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"x1PNX8prXdiT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["val_predictions = np.argmax(val_probabilities, axis=1)\n","# Compute and print the confusion matrix\n","cm = confusion_matrix(val_true_labels, val_predictions)\n","print(\"Confusion Matrix:\")\n","print(cm)\n","\n","unique_classes = np.unique(validation_data[:, 1])\n","target_names = np.unique(validation_data[:,1])\n","\n","# Compute ROC curves and AUC for each class\n","fpr = dict()\n","tpr = dict()\n","roc_auc = dict()\n","\n","for class_id in unique_classes:\n","    # Create a binary target for the current class\n","    binary_labels = np.where(val_true_labels == class_id, 1, 0)\n","\n","    # Calculate the ROC curve and AUC for the current class\n","    fpr[class_id], tpr[class_id], _ = roc_curve(binary_labels, val_probabilities[:, class_id])\n","    roc_auc[class_id] = auc(fpr[class_id], tpr[class_id])\n","\n","# Aggregate TPR and FPR for all classes\n","all_tpr = np.concatenate([tpr[class_id] for class_id in unique_classes])\n","mean_fpr = np.linspace(0, 1, 100)\n","\n","# Compute the mean TPR by interpolating at the mean FPR\n","mean_tpr = np.zeros_like(mean_fpr)\n","for class_id in unique_classes:\n","    mean_tpr += np.interp(mean_fpr, fpr[class_id], tpr[class_id])\n","\n","mean_tpr /= len(unique_classes)\n","mean_auc = auc(mean_fpr, mean_tpr)\n","\n","# Plot the aggregated ROC curve\n","plt.figure()\n","plt.plot(mean_fpr, mean_tpr, lw=2, label='Aggregate ROC curve (AUC = %0.2f)' % mean_auc)\n","plt.plot([0, 1], [0, 1], 'k--', lw=2)\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('ROC Curve (Aggregated)')\n","plt.legend(loc=\"lower right\")\n","plt.show()\n","\n","# Plot the confusion matrix\n","plt.figure()\n","ax = sns.heatmap(cm, annot=False, fmt=\"d\", cmap=\"YlGnBu\")\n","ax.set_title('Confusion Matrix')\n","tick_frequency = 10\n","x_tick_locs = np.arange(len(unique_classes))\n","x_tick_labels = unique_classes\n","plt.xticks(ticks=x_tick_locs[::tick_frequency], labels=x_tick_labels[::tick_frequency], fontsize=8, rotation=90)\n","y_tick_locs = np.arange(len(unique_classes))\n","y_tick_labels = unique_classes\n","plt.yticks(ticks=y_tick_locs[::tick_frequency], labels=y_tick_labels[::tick_frequency], fontsize=8)\n","\n","plt.xlabel('Predicted Label')\n","plt.ylabel('True Label')\n","plt.show()"],"metadata":{"id":"0rVGUg6YW8Nj"},"execution_count":null,"outputs":[]}]}